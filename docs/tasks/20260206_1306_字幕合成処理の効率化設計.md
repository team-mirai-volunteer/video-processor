# 設計書: 字幕合成処理の効率化

## 目的

開発者がサーバーリソース（メモリ・ディスク・処理時間）を効率的に使用できるようにするため。
現在の字幕合成処理は、動画のダウンロード・PNG生成・overlay合成という複数ステップを経由しており、大きな動画ではメモリ消費が問題になる可能性がある。

## 現状の処理フロー

```
┌─────────────────────────────────────────────────────────────────────┐
│ ComposeSubtitledClipUseCase                                         │
├─────────────────────────────────────────────────────────────────────┤
│ 1. GCSから動画をダウンロード → ローカルファイル                        │
│ 2. (オプション) フォーマット変換（縦/横動画）                          │
│ 3. ClipSubtitleComposeClient.compose() を呼び出し                    │
│ 4. 完成動画をGCSにアップロード                                        │
└─────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────┐
│ ClipSubtitleComposeClient.compose()                                 │
├─────────────────────────────────────────────────────────────────────┤
│ 1. 各字幕セグメントごとにPNG画像を生成                                │
│    └─ FFmpegSubtitleGeneratorClient.generate()                      │
│       └─ drawtext フィルタで透明背景PNG生成                          │
│ 2. 元動画にPNG画像をoverlay合成                                      │
│    └─ FFmpeg complexFilter でタイムスタンプ指定overlay               │
└─────────────────────────────────────────────────────────────────────┘
```

### 現状の問題点

1. **ダウンロードのオーバーヘッド**: 動画全体をローカルに保存してからFFmpegに渡している
2. **PNG生成の中間ステップ**: 字幕テキストをPNG画像に変換してからoverlay合成している
3. **複数回のFFmpeg呼び出し**: PNG生成（セグメント数分）+ overlay合成（1回）

## 改善案

### 案1: drawtext直接描画方式（推奨）

FFmpegの`drawtext`フィルタを使って、動画に直接テキストを描画する。

```
┌─────────────────────────────────────────────────────────────────────┐
│ 改善後のフロー                                                       │
├─────────────────────────────────────────────────────────────────────┤
│ 1. GCSからsigned URLを取得                                          │
│ 2. FFmpegに直接URLを入力として渡す                                   │
│ 3. drawtext フィルタで字幕を直接描画                                 │
│ 4. 出力をストリームでGCSにアップロード                               │
└─────────────────────────────────────────────────────────────────────┘
```

**FFmpegコマンドイメージ:**
```bash
ffmpeg -i "https://storage.googleapis.com/bucket/video.mp4?signed=..." \
  -vf "drawtext=text='字幕1':enable='between(t,0,2)':fontfile=...:fontsize=64:...,
       drawtext=text='字幕2':enable='between(t,2,4)':fontfile=...:fontsize=64:..." \
  -f mp4 pipe:1
```

**メリット:**
- ローカルファイルへのダウンロードが不要
- PNG生成ステップが不要
- FFmpeg呼び出しが1回で完結
- メモリ効率が大幅に向上

**課題:**
- `drawtext`フィルタの`enable`式で複数セグメントを切り替える必要がある
- フォントファイルのパスを絶対パスで指定する必要がある
- HTTPソースでのシーク性能（FFmpegは内部でバッファリングするので問題ない可能性）
- signed URLの有効期限管理

### 案2: ストリーミングダウンロード + overlay維持

現在のoverlay方式を維持しつつ、ダウンロードをストリーム化する。

**メリット:**
- 既存のPNG overlay方式を維持（動作確認済み）
- 変更範囲が小さい

**デメリット:**
- PNG生成の中間ステップは残る
- FFmpeg呼び出し回数は変わらない

**注記:** この方式は今回のPRで既に実装済み（`pipeline()`を使用）。

## 影響範囲

### 案1を採用する場合の変更ファイル

| ファイル | 変更内容 |
|---------|---------|
| `ClipSubtitleComposeClient` | drawtext直接描画方式に書き換え |
| `ClipSubtitleComposerGateway` | インターフェース変更（URLベース入力対応） |
| `ComposeSubtitledClipUseCase` | signed URL取得・パイプライン構築 |
| `FFmpegSubtitleGeneratorClient` | 不要になる可能性（または共通化） |

### 技術的な検証事項

1. **drawtext + enable式の動作確認**: 複数セグメントの切り替えが正しく動作するか
2. **HTTPソース入力のパフォーマンス**: FFmpegがHTTP入力でどの程度シークするか
3. **出力ストリーミング**: FFmpegの出力を直接GCSにストリームアップロードできるか
4. **フォント指定**: Cloud Run環境でのフォントパス解決

## 検証用コマンド例

```bash
# drawtext + enable式のテスト
ffmpeg -i input.mp4 \
  -vf "drawtext=text='Subtitle 1':enable='between(t,0,2)':fontsize=64:fontcolor=white:x=(w-text_w)/2:y=h*0.8,
       drawtext=text='Subtitle 2':enable='between(t,2,4)':fontsize=64:fontcolor=white:x=(w-text_w)/2:y=h*0.8" \
  -c:a copy output.mp4

# HTTP入力のテスト
ffmpeg -i "https://example.com/video.mp4" -vf "drawtext=..." -f mp4 pipe:1 | head -c 1000
```

## 実装ステップ（案1の場合）

1. **検証**: ローカル環境でdrawtext直接描画のプロトタイプを作成し、品質を確認
2. **Gateway変更**: `ClipSubtitleComposerGateway`のインターフェースを変更
3. **Client実装**: 新しい`ClipSubtitleComposeClient`を実装
4. **UseCase更新**: signed URL取得とストリーミング出力に対応
5. **テスト**: 既存テストの更新と新規テストの追加
